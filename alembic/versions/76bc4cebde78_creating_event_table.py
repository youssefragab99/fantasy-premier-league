"""creating_event_table

Revision ID: 76bc4cebde78
Revises: 6cfa7c51aaa0
Create Date: 2025-08-11 13:34:37.309031

"""

from collections.abc import Sequence

import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "76bc4cebde78"
down_revision: str | Sequence[str] | None = "6cfa7c51aaa0"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###

    # 1. Create the data_events table
    op.create_table(
        "data_events",
        sa.Column("id", sa.BigInteger(), autoincrement=True, nullable=False),
        sa.Column(
            "event_timestamp", postgresql.TIMESTAMP(timezone=True), server_default=sa.text("now()"), nullable=False
        ),
        sa.Column("source_table_name", sa.Text(), nullable=False),
        sa.Column("source_row_id", sa.Text(), nullable=False),
        sa.Column("operation_type", sa.String(length=10), nullable=False),
        sa.Column("changed_by", sa.Text(), nullable=True),
        sa.Column("old_row_data", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("new_row_data", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index("idx_events_on_table_and_row", "data_events", ["source_table_name", "source_row_id"], unique=False)
    op.create_index("idx_events_on_timestamp", "data_events", ["event_timestamp"], unique=False)

    # 2. Create the trigger function
    op.execute("""
    CREATE OR REPLACE FUNCTION log_data_changes()
    RETURNS TRIGGER AS $$
    DECLARE
        changed_by_user TEXT;
    BEGIN
        -- Try to get a user identifier from the current session settings
        -- This can be set by your application, e.g., SET my.app_user_id = 'user123';
        changed_by_user := current_setting('my.app_user_id', true);

        IF (TG_OP = 'INSERT') THEN
            INSERT INTO data_events (source_table_name, source_row_id, operation_type, changed_by, new_row_data)
            VALUES (TG_TABLE_NAME, NEW.id::TEXT, 'INSERT', changed_by_user, to_jsonb(NEW));
            RETURN NEW;

        ELSIF (TG_OP = 'UPDATE') THEN
            INSERT INTO data_events (source_table_name, source_row_id, operation_type, changed_by, old_row_data, new_row_data)
            VALUES (TG_TABLE_NAME, NEW.id::TEXT, 'UPDATE', changed_by_user, to_jsonb(OLD), to_jsonb(NEW));
            RETURN NEW;

        ELSIF (TG_OP = 'DELETE') THEN
            INSERT INTO data_events (source_table_name, source_row_id, operation_type, changed_by, old_row_data)
            VALUES (TG_TABLE_NAME, OLD.id::TEXT, 'DELETE', changed_by_user, to_jsonb(OLD));
            RETURN OLD;

        END IF;
        RETURN NULL; -- result is ignored since this is an AFTER trigger
    END;
    $$ LANGUAGE plpgsql;
    """)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # 1. Drop the trigger function
    # The CASCADE will automatically remove any triggers that use this function
    op.execute("DROP FUNCTION IF EXISTS log_data_changes() CASCADE;")

    # 2. Drop the table and its indexes
    op.drop_index("idx_events_on_timestamp", table_name="data_events")
    op.drop_index("idx_events_on_table_and_row", table_name="data_events")
    op.drop_table("data_events")
    # ### end Alembic commands ###
